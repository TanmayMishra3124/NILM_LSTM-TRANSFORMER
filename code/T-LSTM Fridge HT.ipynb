{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8459bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilmtk import DataSet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b0243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (change path if needed)\n",
    "dataset = DataSet(\"D:/lusip/ukdale.h5/ukdale.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ff129d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:509: UserWarning: Found duplicate index. Keeping first value\n",
      "  warnings.warn(\"Found duplicate index. Keeping first value\")\n",
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:501: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  return fill_method(how(data.resample(rule, **resample_kwargs)))\n",
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:501: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  return fill_method(how(data.resample(rule, **resample_kwargs)))\n"
     ]
    }
   ],
   "source": [
    "elec = dataset.buildings[1].elec\n",
    "\n",
    "# Load active power only\n",
    "mains_df = next(elec.mains().load(sample_period=6))[('power', 'active')].to_frame()\n",
    "mains_df.columns = ['mains']\n",
    "\n",
    "fridge_df = next(elec['fridge'].load(sample_period=6))[('power', 'active')].to_frame()\n",
    "fridge_df.columns = ['fridge']\n",
    "\n",
    "# Align timestamps\n",
    "aligned_df = mains_df.join(fridge_df, how='inner')\n",
    "aligned_df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71852bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mains_scaler = MinMaxScaler()\n",
    "fridge_scaler = MinMaxScaler()\n",
    "\n",
    "aligned_df['mains'] = mains_scaler.fit_transform(aligned_df[['mains']])\n",
    "aligned_df['fridge'] = fridge_scaler.fit_transform(aligned_df[['fridge']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821f20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        X.append(df['mains'].values[i:i + window_size])\n",
    "        y.append(df['fridge'].values[i + window_size // 2])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 99\n",
    "X, y = create_sequences(aligned_df, WINDOW_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c47b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(-1, WINDOW_SIZE, 1)  # Shape: (samples, 99, 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a157138b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# üîß Define your model class\n",
    "class LSTMTransformer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, ff_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.transformer(x)\n",
    "        center = x[:, x.size(1) // 2, :]\n",
    "        return self.fc(center).squeeze()\n",
    "\n",
    "# üéØ Define Optuna objective\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "    hidden_size_choices = [h for h in range(32, 129, 8) if h % num_heads == 0]\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', hidden_size_choices)\n",
    "    ff_dim = trial.suggest_int('ff_dim', 64, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "\n",
    "    # ‚ö° Use subset for faster training\n",
    "    subset_size = 300_000\n",
    "    X_sub = X_train[:subset_size]\n",
    "    y_sub = y_train[:subset_size]\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_sub, dtype=torch.float32),\n",
    "        torch.tensor(y_sub, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Build model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = LSTMTransformer(hidden_size, num_heads, ff_dim, num_layers).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # üîÅ Train for 5 epochs\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # üìà Evaluate on test set\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in DataLoader(\n",
    "            TensorDataset(\n",
    "                torch.tensor(X_test, dtype=torch.float32),\n",
    "                torch.tensor(y_test, dtype=torch.float32)\n",
    "            ),\n",
    "            batch_size=batch_size\n",
    "        ):\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(yb.numpy())\n",
    "\n",
    "    # Inverse scale\n",
    "    preds_inv = fridge_scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "    actuals_inv = fridge_scaler.inverse_transform(np.array(actuals).reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Return MAE to minimize\n",
    "    return mean_absolute_error(actuals_inv, preds_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e316fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-03 23:04:32,935] A new study created in memory with name: no-name-7f63a812-afeb-4493-989c-d7c2169f4042\n",
      "[I 2025-07-03 23:51:44,833] Trial 0 finished with value: 31.293428421020508 and parameters: {'num_heads': 4, 'hidden_size': 128, 'ff_dim': 140, 'num_layers': 1, 'lr': 0.0010223717867684189, 'batch_size': 128}. Best is trial 0 with value: 31.293428421020508.\n",
      "[I 2025-07-04 01:29:36,041] Trial 1 finished with value: 26.998451232910156 and parameters: {'num_heads': 8, 'hidden_size': 72, 'ff_dim': 208, 'num_layers': 2, 'lr': 0.00014062462052452567, 'batch_size': 128}. Best is trial 1 with value: 26.998451232910156.\n",
      "[I 2025-07-04 09:15:08,025] Trial 2 finished with value: 45.341796875 and parameters: {'num_heads': 8, 'hidden_size': 72, 'ff_dim': 231, 'num_layers': 3, 'lr': 0.0017650216000706523, 'batch_size': 64}. Best is trial 1 with value: 26.998451232910156.\n",
      "[I 2025-07-04 11:06:15,931] Trial 3 finished with value: 23.254003524780273 and parameters: {'num_heads': 4, 'hidden_size': 96, 'ff_dim': 247, 'num_layers': 3, 'lr': 0.00018107399357726567, 'batch_size': 128}. Best is trial 3 with value: 23.254003524780273.\n",
      "[I 2025-07-04 12:27:53,963] Trial 4 finished with value: 46.51721954345703 and parameters: {'num_heads': 2, 'hidden_size': 96, 'ff_dim': 166, 'num_layers': 3, 'lr': 0.001959854197080364, 'batch_size': 128}. Best is trial 3 with value: 23.254003524780273.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 23.254003524780273\n",
      "Best Hyperparameters: {'num_heads': 4, 'hidden_size': 96, 'ff_dim': 247, 'num_layers': 3, 'lr': 0.00018107399357726567, 'batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=5)\n",
    "\n",
    "print(\"Best MAE:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
