{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca13cc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:509: UserWarning: Found duplicate index. Keeping first value\n",
      "  warnings.warn(\"Found duplicate index. Keeping first value\")\n",
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:501: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  return fill_method(how(data.resample(rule, **resample_kwargs)))\n",
      "c:\\Users\\tanmay\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\nilmtk\\utils.py:501: FutureWarning: 'S' is deprecated and will be removed in a future version, please use 's' instead.\n",
      "  return fill_method(how(data.resample(rule, **resample_kwargs)))\n"
     ]
    }
   ],
   "source": [
    "from nilmtk import DataSet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load UK-DALE dataset\n",
    "dataset = DataSet(\"D:/lusip/ukdale.h5/ukdale.h5\")\n",
    "elec = dataset.buildings[1].elec\n",
    "\n",
    "# Load active power for mains\n",
    "mains_df = next(elec.mains().load(sample_period=6))[('power', 'active')].to_frame()\n",
    "mains_df.columns = ['mains']\n",
    "\n",
    "# Load active power for kettle\n",
    "kettle_df = next(elec['kettle'].load(sample_period=6))[('power', 'active')].to_frame()\n",
    "kettle_df.columns = ['kettle']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef30be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align by timestamp\n",
    "aligned_df = mains_df.join(kettle_df, how='inner')\n",
    "aligned_df.dropna(inplace=True)\n",
    "\n",
    "# Remove kettle peaks > 3000W\n",
    "aligned_df = aligned_df[aligned_df['kettle'] <= 3000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "425ccb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit scalers\n",
    "mains_scaler = MinMaxScaler()\n",
    "kettle_scaler = MinMaxScaler()\n",
    "\n",
    "aligned_df['mains'] = mains_scaler.fit_transform(aligned_df[['mains']])\n",
    "aligned_df['kettle'] = kettle_scaler.fit_transform(aligned_df[['kettle']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35716b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(df, window_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(df) - window_size):\n",
    "        X.append(df['mains'].values[i:i + window_size])\n",
    "        y.append(df['kettle'].values[i + window_size // 2])  # seq2point\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "WINDOW_SIZE = 99\n",
    "X, y = create_sequences(aligned_df, WINDOW_SIZE)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X = X.reshape(-1, WINDOW_SIZE, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc9db12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (7474748, 99, 1)\n",
      "X_test shape: (1868688, 99, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b94a7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import optuna\n",
    "import numpy as np\n",
    "\n",
    "# 🔧 Define model\n",
    "class LSTMTransformer(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, ff_dim, num_layers):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size=hidden_size, batch_first=True)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=ff_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.transformer(x)\n",
    "        center = x[:, x.size(1) // 2, :]\n",
    "        return self.fc(center).squeeze()\n",
    "\n",
    "# 🎯 Define Optuna objective for kettle\n",
    "def objective(trial):\n",
    "    # Sample hyperparameters\n",
    "    num_heads = trial.suggest_categorical('num_heads', [2, 4, 8])\n",
    "    hidden_size_choices = [h for h in range(32, 129, 8) if h % num_heads == 0]\n",
    "    hidden_size = trial.suggest_categorical('hidden_size', hidden_size_choices)\n",
    "    ff_dim = trial.suggest_int('ff_dim', 64, 256)\n",
    "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
    "    lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n",
    "\n",
    "    # ⚡ Subset for speed\n",
    "    subset_size = 300_000\n",
    "    X_sub = X_train[:subset_size]\n",
    "    y_sub = y_train[:subset_size]\n",
    "\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_sub, dtype=torch.float32),\n",
    "        torch.tensor(y_sub, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Initialize model\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "    print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "    model = LSTMTransformer(hidden_size, num_heads, ff_dim, num_layers).to(device)\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # 🔁 Train for 10 epochs\n",
    "    model.train()\n",
    "    for epoch in range(5):\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(xb)\n",
    "            loss = criterion(output, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 📈 Evaluate\n",
    "    model.eval()\n",
    "    predictions, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in DataLoader(\n",
    "            TensorDataset(\n",
    "                torch.tensor(X_test, dtype=torch.float32),\n",
    "                torch.tensor(y_test, dtype=torch.float32)\n",
    "            ),\n",
    "            batch_size=batch_size\n",
    "        ):\n",
    "            xb = xb.to(device)\n",
    "            preds = model(xb).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(yb.numpy())\n",
    "\n",
    "    # Inverse transform\n",
    "    preds_inv = kettle_scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "    actuals_inv = kettle_scaler.inverse_transform(np.array(actuals).reshape(-1, 1)).flatten()\n",
    "\n",
    "    return mean_absolute_error(actuals_inv, preds_inv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035c48c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 16:59:34,857] A new study created in memory with name: no-name-059c45ca-8f86-463e-be6d-f2fe761e702a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:05:18,466] Trial 0 finished with value: 17.005935668945312 and parameters: {'num_heads': 2, 'hidden_size': 56, 'ff_dim': 183, 'num_layers': 3, 'lr': 0.004499546765618546, 'batch_size': 128}. Best is trial 0 with value: 17.005935668945312.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:13:24,769] Trial 1 finished with value: 8.636940002441406 and parameters: {'num_heads': 4, 'hidden_size': 72, 'ff_dim': 208, 'num_layers': 3, 'lr': 0.00011090132629828084, 'batch_size': 256}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:20:48,033] Trial 2 finished with value: 22.613035202026367 and parameters: {'num_heads': 8, 'hidden_size': 64, 'ff_dim': 121, 'num_layers': 2, 'lr': 0.009003362351250509, 'batch_size': 64}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:29:06,283] Trial 3 finished with value: 16.04014778137207 and parameters: {'num_heads': 4, 'hidden_size': 72, 'ff_dim': 235, 'num_layers': 3, 'lr': 0.00018193307195625487, 'batch_size': 256}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:38:20,427] Trial 4 finished with value: 19.457141876220703 and parameters: {'num_heads': 4, 'hidden_size': 88, 'ff_dim': 156, 'num_layers': 3, 'lr': 0.0019060091109844757, 'batch_size': 64}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:42:31,460] Trial 5 finished with value: 18.314985275268555 and parameters: {'num_heads': 4, 'hidden_size': 32, 'ff_dim': 136, 'num_layers': 2, 'lr': 0.00094826234290251, 'batch_size': 128}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:48:16,446] Trial 6 finished with value: 15.183328628540039 and parameters: {'num_heads': 8, 'hidden_size': 104, 'ff_dim': 74, 'num_layers': 1, 'lr': 0.00372452091988567, 'batch_size': 64}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:52:25,846] Trial 7 finished with value: 22.323503494262695 and parameters: {'num_heads': 2, 'hidden_size': 120, 'ff_dim': 76, 'num_layers': 1, 'lr': 0.004161147038665051, 'batch_size': 256}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 17:55:33,451] Trial 8 finished with value: 30.51527976989746 and parameters: {'num_heads': 2, 'hidden_size': 96, 'ff_dim': 138, 'num_layers': 1, 'lr': 0.00030033187435503074, 'batch_size': 256}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-06 18:03:36,557] Trial 9 finished with value: 18.654237747192383 and parameters: {'num_heads': 2, 'hidden_size': 88, 'ff_dim': 114, 'num_layers': 3, 'lr': 0.005981972981678149, 'batch_size': 64}. Best is trial 1 with value: 8.636940002441406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Best MAE: 8.636940002441406\n",
      "✅ Best Hyperparameters: {'num_heads': 4, 'hidden_size': 72, 'ff_dim': 208, 'num_layers': 3, 'lr': 0.00011090132629828084, 'batch_size': 256}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create study\n",
    "study = optuna.create_study(direction='minimize')\n",
    "# Run tuning\n",
    "study.optimize(objective, n_trials=10)\n",
    "# Show best results\n",
    "print(\"\\n✅ Best MAE:\", study.best_value)\n",
    "print(\"✅ Best Hyperparameters:\", study.best_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
